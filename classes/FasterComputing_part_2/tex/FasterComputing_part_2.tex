\documentclass[12pt,letterpaper]{article}

\usepackage[latin1]{inputenc}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{graphicx}
\usepackage{hyperref} % enable links within pdf
\hypersetup{colorlinks = true, linkcolor = black, urlcolor = blue}

\setcounter{secnumdepth}{0}  % don't number sections (stars not needed)

% For making a multi-page box
\usepackage[most]{tcolorbox}


\title{High Performance Computing}
\author{}
\date{}

\begin{document}
\maketitle
\tableofcontents

\clearpage

Today we'll be interacting with one of OSU's \emph{High Performance Computing} clusters.
HPC clusters consist of many servers (computers) that are all networked together.
Each server is called a node.
You can choose to work on only a single node
(which will probably already be faster than your personal computer)
or on several nodes at once.
The point of using several nodes is that you can use them in parallel
(just like we did last class when we used our own computer's cores in parallel).
\unskip
\footnote{Since each node also has many cores, you can also parallelize on each of several parallel nodes too!}
The cluster we'll use today is called the Novus HPC cluster \url{https://arcs.oregonstate.edu/novus-cluster} that is maintained by OSU's Advance Research Computing Services.
\unskip
\footnote{Apparently all of OSU's clusters will soon be joined and managed by the CQLS.}

\section{Tools}
In order to access the cluster from off-campus, you'll need to be connected to OSU's Virtual Private
Network (VPN).
OSU uses the \emph{CISCO AnyConnect} client, so if you haven't already installed it, do so now.
See download and instructions at
\url{https://oregonstate.teamdynamix.com/TDClient/1935/Portal/KB/ArticleDet?ID=76790}.
You'll need to confirm your access privileges using \emph{Duo} and your ONID credentials.

To move files between your computer and the cluster,
you'll also need an \texttt{sftp} client, like \url{https://cyberduck.io}.\footnote{File transfer can also be done by
\texttt{ssh} command-line, but there are no commands to remember with \texttt{sftp}.}
Finally, in order to pass commands to the cluster, you'll need an \texttt{ssh} client.
Mac users can use \emph{Terminal}, which is built into the operating system.
Windows users will need to install one (e.g., \url{https://mobaxterm.mobatek.net}, which also does
\texttt{sftp}).

If you really don't like using the above two methods of interacting with the cluster, you could also use the \texttt{OnDemand} web interface: \url{https://novus.dri.oregonstate.edu/}.




\section{\texttt{sftp} file transfer}

Open up your \texttt{sftp} client and establish a connection to the Novus cluster using the address:
\url{sftp://novus.dri.oregonstate.edu}.
In \emph{Cyberduck}:
\begin{enumerate}
	\item click on ``\emph{Open Connection}'',
	\item select ``\emph{SFTP (Secure File Transfer Protocol)}'',
	\item type in the Server address:\\
	\url{sftp://novus.dri.oregonstate.edu}\\
	(the default \emph{port 22} should be fine),
	\item enter your ONID username and password,
	\item leave \emph{SSH Private Key} as ``\emph{None}'', and
	\item check the \emph{Add to Keychain} box in order to save your credentials.
	\unskip\footnote{The option and label for this check-box may be specific to Macs.}
\end{enumerate}
\noindent
You should now be in your \texttt{home} folder (e.g.,~\texttt{/home/novakm/}).
Take a moment now to bookmark this connection.
(In \emph{Cyberduck}, select the \emph{Add Bookmark} option from the drop-down menu.)

In your \texttt{home} folder you should see several existing folders (e.g.,~\texttt{ondemand}, \texttt{novus}, \texttt{globus}).
There are also several ``hidden'' files and directories that you may or may not see depending on your \textit{Cyberduck} settings.
\unskip
\footnote{The filenames of hidden files and directories all start with a period (e.g., \texttt{.bash\_profile}).
Don't worry if you don't see them as you'll rarely if ever need them.  
In fact, you typically don't want to delete them, so be careful if you do see them.}
Create a new folder \textbf{inside the \texttt{novus} folder}.
Call it something informative, like the abbreviated name of your project.
Open the folder and drag-and-drop your project files inside it.
\unskip
\footnote{Rather than using \texttt{sftp}, 
you could also use \texttt{ssh} and the command \\
\texttt{rsync -avz ./{folder\_name}/ ONID@novus.dri.oregonstate.edu:/home/ONID/{folder\_name}/}
to copy from your desktop to the cluster.}
Be sure to maintain your project's directory substructure so that all relative links between scripts and data work!
In fact, you may want (or need) to put much of your whole repository in place (i.e.~have your \texttt{data}, \texttt{code}, and \texttt{output} folders and contents all present).

\section{\texttt{ssh} communication and initial \texttt{R} setup}
Now switch over to your \texttt{s}ecure \texttt{sh}ell (\texttt{ssh}) client (e.g.,~\emph{MobaXTerm} for Windows users, or \emph{Terminal} for Mac users
\unskip
\footnote{If you want, you can access \emph{Terminal} from within \emph{RStudio}. 
	The tab for it should be in the same window as the console.}).
At the \$ prompt, type in

\texttt{ssh \emph{yourONID}@novus.dri.oregonstate.edu}

\noindent
whereupon you'll be prompted for your ONID password and possibly also \textit{Duo} confirmation.
You should then see a welcome screen with a new prompt at the bottom of the window:

\texttt{[novakm@submit1 $\sim$]\$}

\noindent
Since we want to run \emph{R}, we'll have to ``activate'' it using the \texttt{load} command.
To see what version(s) of \emph{R} are available, and to see all the other tools (``modules'') that are available as well, type

\texttt{module avail}

\noindent
To load a specific module, for example \emph{R v.4.4.1}, type:

\texttt{module load R/4.4.1}

 \noindent
 Now launch \emph{R} by typing-in

 \texttt{R}

 \noindent
 If you're going to need any \emph{R} packages, you'll need to install them into your home directory using

 \texttt{install.packages(c("\emph{package1", "package2"}))}

 \noindent
The first time you run the \texttt{install.packages()} command, you'll be asked if you want to create a personal library.
Answer by typing \texttt{y} for yes.

\noindent
Notice that you're actually inside an \emph{R} session! 
You could, therefore, work away ``interactively'' as if you were in an R session on your own computer.
(The downside is that you don't have the benefit of writing scripts or having the ability to create graphics.)

To get out of \emph{R} and back to the \texttt{ssh} prompt, type \texttt{q()} for quit.
Don't save your workspace!


\section{\texttt{ssh} navigation}
Now lets find the files we uploaded using the \texttt{ssh} view of the cluster.
Back at the \texttt{ssh} prompt, use the list (\texttt{ls}) command:

\texttt{[novakm@submit1 $\sim$]\$} \texttt{ls}

\noindent
The \texttt{ls} command will show you all the sub-directories and files within the directory you're currently in (which at this point in time is your \texttt{home} directory).
You should see the files (or the folder) you uploaded and, if you installed any \emph{R} packages, a folder named \texttt{R\_libs}.
In order to enter a subdirectory, use the change directory (\texttt{cd}) command followed by the name of the directory you'd like to enter:

\texttt{[novakm@submit1 $\sim$]\$} \texttt{cd} \emph{subdirectory}

\noindent
You can move down into multiple nested dirctories, e.g.,

\texttt{[novakm@submit1 $\sim$]\$}  \texttt{cd} \emph{subdirectory/subsubdirectory}

\noindent
and move out of any number of directories, e.g.,

\texttt{[novakm@submit1 $\sim$]\$}  \texttt{cd} \emph{../../otherdirectory}

\noindent
just as we did when setting relative paths in \emph{R}.

A very useful feature here is that you don't need to type out the whole name of a directory or file.
Just type the first letter of its name and then hit your tab key.
The name will autofill until it gets to a letter where it can't distinguish between similarly named files.
Type the distinguishing letter and tab to continue until you've got the whole name.

Once you're in the directory in which you'd like to be, type \texttt{ls} to confirm all the contents are there as needed.
If you'd like to take a quick look at the contents of a file, you can use the concatenate (\texttt{cat}) command:

\texttt{[novakm@submit1 \emph{subdirectory}]\$} \texttt{cat} \emph{file.r}

\noindent
The contents won't be rendered very nicely, but the function is nonetheless useful for confirming the contents of short scripts (such as the \texttt{submit.sh} submission script that we'll talk about below).



\section{\texttt{ssh} job submission (non-parallel jobs)}
When performing analyses on a cluster, you (typically) don't do so be entering into the module 
(e.g.,~within \emph{R}, the way we did above when installing \emph{R} packages).
Rather, you use a submission script to submit your code to the cluster as a ``job".
The primary reason for doing that is that the cluster has extensive automated job managment tools which optimize the use of nodes among users.
Therefore, when you submit a job, the cluster (typically) determines which of its nodes it will send the job to and when.
It's similarly so when your job contains code that performs parallelized computations.

\begin{tcolorbox}[breakable, enhanced, before upper={\parindent15pt}]
	\noindent
	You can find links to copies of both \texttt{submit\_simple.sh} and a minimalist \texttt{simple.R} that it runs on the \texttt{README} page of today's lesson.
\end{tcolorbox}

The submission script for a simple (non-parallel) \emph{R} job on our cluster will look like this
\unskip
\footnote{
	Note that the \# symbols are \emph{not} for commenting-out lines of code.  They're necessary!
	(The \#\$, for example, denotes a command-line argument to be passed to the job 
	scheduler.)}:
\begin{verbatim}
	#!/bin/bash
	#SBATCH -J simple
	#SBATCH -o output_%A_%a.txt
	#SBATCH -e errors_%A_%a.txt
	
	#SBATCH --mail-type=ALL
	#SBATCH --mail-user=ONID@oregonstate.edu
	
	#SBATCH --partition=test.q
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=1
	#SBATCH --cpus-per-task=1
	
	# Load the R Module
	module load R/4.4.1
	
	# Commands to run job
	Rscript simple.R $SLURM_ARRAY_TASK_ID
\end{verbatim}

Copy the above into a text file.
Edit it as needed.  
At minimum, you'll want to
\begin{enumerate}
	\item rename the \texttt{-J simple} name of the job to give it an informative project-specific name;
	\item edit your email address; and	
	\item change the name of the \emph{R} script at the bottom so that the appropriate \emph{R} analysis script is called.
\end{enumerate}
Save the file with an \texttt{.sh} extension (e.g.,~\texttt{submit\_simple.sh}).
Now use your \texttt{sftp} client to upload this submission script into the same directory as the \texttt{simple.R} analysis script that it calls.
Ensure it's in place using your \texttt{ssh} client.

Let's assume that our analysis script and our submission script are located in a directory named \texttt{mytest}.
Use \texttt{cd} to change into the directory and \texttt{ls} to ensure both your script and your submission script are present.
To submit your job, use the \texttt{sbatch} command:

\texttt{[novakm@submit1 mytest]\$} \texttt{sbatch submit\_simple.sh}
\\


\section{Job status, completion, and ending a job}

\noindent
You can use \texttt{squeue} to confirm that your job has been correctly submitted and check on its status
(i.e.~whether it is already running, is still in the queue, etc.).
Use

\texttt{[novakm@submit1 mytest]\$} \texttt{squeue -u \textit{yourONID}}

\noindent
to see your jobs, and

\texttt{[novakm@submit1 mytest]\$} \texttt{squeue}

\noindent
to see everyone else's too.
Note that every job has its own \texttt{JOBID} identifier.

\noindent
If your job is in the queue waiting to be run, you can use 

\texttt{squeue -j <\emph{JOBID}> --start}

\noindent
to get an estimate of how long it will be before it starts running.

\begin{tcolorbox}[breakable, enhanced, before upper={\parindent15pt}]
	\noindent
	Note that the \texttt{simple.R} job you submitted above will likely run so fast that it won't even be visible in your list of jobs for longer than just a few seconds.  You may therefore want to submit a job that takes longer.  On today's README page, you'll find a link to \texttt{simple\_sleep.R} for that purpose.  Remember to update your submission script so that it runs this \texttt{R} script.
\end{tcolorbox}

If you typed in your correct email address in the submission script, you'll get an email when the job completes successfully or ends in an error.
A log of your job will also be saved to the output file you specified in your submission script (which can be useful for debugging).
The log will include output that your script printed to screen (i.e.~what would have appeared in your \texttt{R} console had you run the script on your computer).
Use your \texttt{sftp} client to download all the output your script produced.


Should you decide that something isn't working right for an active job
(e.g.,~a job is taking far longer than expected, eating up too much of the cluster's resources, or you realize you do in fact have a bug in it), 
you can end it prematurely using the \texttt{scancel} command:
\begin{enumerate}
	\item get its \emph{JOBID} from the first column of the \texttt{squeue} view;
	\item type \texttt{scancel} followed by the \emph{JOBID}.
\end{enumerate}

Finally, to close your \texttt{ssh} session, use the \texttt{exit} command.
A list of additional commands is included on the resources page of the Novus cluster (see ``Command line conversions''): 
\url{https://arcs.oregonstate.edu/novus-cluster}. 


\section{Parallel computing}

Parallelization on a cluster can take many forms.
You might run the same script many independent times on a different node, each time pulling in a different dataset.
Or your script might repeat a particular calculation many independent times (just as we did last class we implemented parallelization across our processor's cores), then pull all those calculations back together before proceeding.
Or you might have several semi-independent scripts that take different amounts of time to complete and are interdependent in that they rely on each other's output to proceed.
As opposed to serial jobs, the number of possible parallel job forms is quite large.
We'll only touch on the possibilities with two examples.








\end{document}
